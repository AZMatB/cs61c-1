Daniel Nakashima 
username cs61c-hi
CS61C Spring 2012
TA: Eric Liang
Due Sunday, March 11, @ 23:59:00

====================================================================================
Problem 1: Cache Dimensions

How many 32-bit integers can be stored in a byte-addressed direct-mapped cache with 15 tag bits, 15 index bits, and 2 offset bits? Write your answer as a power of 2.

byte addressed
32 bit ints
tag_bits 	= 15;
index_bits 	= 15;
offset_bits = 2;

15 index bits => 2^15 lines = 32768 lines
2 offset_bits => 2 word/block * 32 bits/word * 1 int/32 bits = 2 ints/block
2 ints/block * 2^15 blocks/cache = 2^16 ints/cache

====================================================================================

Assume 16-bit byte addresses. You are trying to access memory byte address 0x3434. What are the corresponding tag, index and offset for 
	
	addrsize = tag_field + index_size + offset_size
	addr = (tag)(offset)(index)		//has following format
	address 0x3434 => 0011 0100 0011 0100 b 

32-line direct-mapped cache with 1 word blocks?

	32 lines => 2^5 lines => 5 index bits
	1 word blocks => 2^(1+2) bytes => 1 bit offset
	tag_field 	= 	addr_size - index_size -offset_size = 16 - 5 - 1 = 10
	tag_field = memory_byte(0-9) = 	0011 0100 00
	offset = memory_byte(10) => 	1
	index => memory_byte(11-15) => 	1 0100 
====================================================================================

16-line direct-mapped cache with 4 word blocks?

	16 lines => 2^4 lines => 4 index bits
	4 word blocks => 2^(4+2) bytes => 4 bit offset
	tag_field 	= 	addr_size - index_size -offset_size = 16 - 4 - 4 = 8
	tag_field = memory_byte(0-7) = 	0011 0100 
	offset = memory_byte(8-11) => 	0011 
	index => memory_byte(12-15) => 	0100 
====================================================================================

1KB direct-mapped cache with 2 word blocks?

	total_size = 1 KB = 2^10 bytes/cache
	2 word/ line * 4 bytes/word = 2^3 bytes/line
	2^10 bytes/cache * 1 block/2^3 bytes = 2^7 lines
	2^7 lines => 7 index bits
	2 word blocks => 2^(4+2) bytes => 2 bit offset
	tag_field 	= 	addr_size - index_size -offset_size = 16 - 7 - 2 = 5
	tag_field = memory_byte(0-4) = 	0 0110
	offset = memory_byte(5-6) => 	10
	index => memory_byte(7-15) => 	0 0011 0100
====================================================================================

What is the ratio of data bits to total bits in a 128 byte write-back direct-mapped cache that has 2-word blocks and byte addresses are 64 bits? 

addrsize = tag_field + index_size + offset_size

byte addresses => 2^0 bytes / address
128 byte cache (DMWB) = 2^7 bytes
2^7 bytes/cache * 1 block/ 2^3 bytes = 2^5 blocks/cache
2^5 blocks/cache => 5 bit index

2 word block => 2^1 * 2*2 = 2^3 bytes/block
2 word block => 2 bit offsets

1 valid bit/line * 2^5 lines/cache = 2^5 valid bits/cache * 1 byte/2^3 bits = 2^2

128 bytes + 2^2 = 132 total bytes
128 data bytes/132 total bytes = 0.97

====================================================================================
What about if it were a write-through cache instead?
2*2^5 valid bits/cache = 2^6 bits * 1 byte/2^3 bits = 2^3
128 bytes + 2^3 = 136 total bytes
128 data bytes/136 total bytes = 0.94


====================================================================================
Problem 2: Cache Accesses (from P&H)

The following C program is run (with no optimizations) on a processor with a direct-mapped cache that has eight-word blocks and holds 256 words of data:

	int i,j,c,stride,array[512];
	...
	for(i=0; i<10000; i++)
	  for (j=0; j<512; j+=stride)
		c += i%(array[j]);
If we consider only the cache activity generated by references to the array and we assume that integers are words, what are possible miss rates (there is more than one for one of them) when

holds 256 words of data thus 

stride = 256?
stride = 255?
Explain your answers clearly in a few sentences.
For the case of 256 if you observe the inner loop, only two types calls will be made each will require array[0] and array[256].
Obviously on the first load to cache you will get a miss since it is currently empty.  On the next one you will have to load the later half from  array[256] - array[512]  which is the limit imposed due to the size of the cache.  Resulting in another miss.  Repeating this will always result in a miss. MISS_RATE = 100%

Now for the case of 255 obviously the first iteration you will also get a miss. but on the second iteration you will get the array[255](miss) loaded in cache as well as the value you will need for the next iteration (hit).  This results will always result in a hit miss hit miss repeating.  MISS_RATE = 50%.

==================================================================================
Problem 3: Cache Performance

Data L1 Cache with hit rate of 80% and Instruction L1 Cache with hit rate of 95%. Accessing main memory takes 100 cycles. If the ideal CPI (no cache misses) is 1 and 25% of instructions are loads and stores, what is the CPI?
	
	1 total_hits - 0.8 data_hits = 0.2 data misses/instr
	1 total_hits - 0.95 instr_hits = 0.05 instr_misses/instr
	0.2 data_misses/data_instr * 0.25 data_instr/instr = 0.05 data_misses/instr
	CPI_due_to_miss = 100 cycles/miss * (0.05 data_misses/instr + 0.05 instr_misses_instr) = 10 cycles/instr
							
	CPI = CPI_ideal + CPI_due_to_miss = 1 + 10 = 11 CPI
	

L1 Cache has a hit rate of 80% and a hit time of 1 cycle. L2 Cache has a local miss rate of 10% and a hit time of 4 cycles. L3 Cache has a local miss rate 5%, and a hit time of 20 cycles. Accessing main memory takes 100 cycles. Find the AMAT.
	L1 Cache miss rate = 1-0.8 = 0.2
	AMAT = 1+0.2[4 + 0.1[20 + 0.05[100+0]]]
	AMAT = 2.3 cycles

====================================================================================
Problem 4: Thread Level Parallelism, Performance

The latter 40% of your program supports multiple threads. You noted the time your entire program took to complete with one thread. In the ideal case, what is the overall speedup you'd expect, running the latter portion with
	
	Amdahl's Law
	speedup = 1/( (1-F) + F/S
	F = fraction of the program that is sped up = 0.4
	S = speedup on that fraction
	assume that running n multiple threads results in n times FASTER

	four threads rather than one?
	S = 4; 	F = 0.4;
	speed_up = 1/((1-0.4) + 0.4/4)
	speed_up = 1.43
	
	eight threads rather than one?
	
	S = 8; 	F = 0.4;
	speed_up = 1/((1-0.4) + 0.4/8)
	speed_up = 1.54
		
	as many as you want?
	let n denote the number of threads you are running that particular part of the program on then...
	
	speedup = 1/( (1-F) + F/S*n

	Why might the actual speedups be less than the ideal ones you calculated? 
		The actual speedup might be less than the ideal calculated because it assumes that there is no slow down that occurs due to file transfers and that the no slow down occurs when you parallelize something.  This is similar to the labs we did for mapreduce, i.e. this apx can be used only for large sets of data.